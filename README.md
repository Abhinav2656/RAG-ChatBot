# ğŸš€ RAG-Based Chatbot using Groq LLM

## ğŸ“š **Objective**
As a RAG (Retrieval-Augmented Generation) enthusiast, I wanted to build and test a chatbot capable of:
- Scraping website content.
- Generating relevant answers using retrieved information.
- Leveraging Groq LLM for enhanced response accuracy.

---

## âš¡ï¸ **Tech Stack**
- ğŸ Python 3.11+
- ğŸ“š LangChain
- ğŸ¦— Hugging Face (Flan-T5)
- ğŸ§  Groq LLM (`langchain_groq`)
- ğŸ” BeautifulSoup (Scraping)
- ğŸŸ£ï¸ FAISS (Vector Store)

---

## ğŸ› ï¸ **Implementation Steps**
1. **Scraping Module:**  
   - Extracts website content using `BeautifulSoup`.
   - Breaks text into manageable chunks.

2. **Embedding Generation:**  
   - Converts chunks into embeddings using `SentenceTransformer`.

3. **Vector Storage:**  
   - Stores embeddings using FAISS for quick retrieval.

4. **Query Processing:**  
   - Retrieves relevant chunks and sends context to Groq LLM.

5. **Answer Generation:**  
   - Generates an appropriate response with fallback if no context is found.

---

## ğŸ’‚ **Folder Structure**
```
â”œâ”€â”€ scrape.py          # Scrapes website content
â”œâ”€â”€ embed.py           # Generates embeddings
â”œâ”€â”€ vector_store.py    # Handles vector storage & retrieval
â”œâ”€â”€ rag_chatbot.py     # Main RAG chatbot logic
â””â”€â”€ requirements.txt   # Required dependencies
```

---

## ğŸ›† **Installation**
```bash
# Clone the repository
git clone https://github.com/username/rag-chatbot.git

# Navigate to the project directory
cd rag-chatbot

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # For Linux/Mac
# or
.venv\Scripts\activate  # For Windows

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸš€ **Usage**
```bash
# Run the chatbot
python rag_chatbot.py
```

---

## âš¡ï¸ **Features**
- âœ… Website scraping & chunking
- âœ… Context-based retrieval
- âœ… High-quality responses with Groq LLM
- âœ… Handles fallback queries gracefully

---

## ğŸ§© **Future Improvements**
- ğŸ¤– Improve response relevance with fine-tuning.
- âš¡ Add support for multiple LLM models.
- ğŸ“ˆ Optimize chunking for large websites.
